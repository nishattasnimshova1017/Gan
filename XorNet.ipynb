{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining XorNet for learning XOR operaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XorNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 10)     # 2 input neurons, 10 hidden neurons\n",
    "        self.fc2 = nn.Linear(10, 1)     # 1 output neuron\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))         # relu is used as non linear activation function \n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, net, learning_rate = 0.01, epoch=100):\n",
    "        self.net = net \n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoch = epoch\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.SGD(self.net.parameters(), self.learning_rate)\n",
    "        self.net.zero_grad()\n",
    "    def generate_data(self):\n",
    "        x = (torch.rand(10, 2)>0.5)       #generate random data; batch size 10\n",
    "        y = np.logical_xor(x[:,0],x[:,1])\n",
    "        y.view(-1,1)\n",
    "        x = Variable(x.type(torch.FloatTensor))\n",
    "        y = Variable(y.type(torch.FloatTensor))\n",
    "        return x, y\n",
    "    def decision_boundary(self, itr=-1):\n",
    "        plt.figure(figsize=(5,5))\n",
    "        x = np.arange(0.0, 1.001, 0.01)\n",
    "        y = np.arange(0.0, 1.001, 0.01)\n",
    "        data = torch.zeros(len(x) * len(y), 2)\n",
    "        for i in range(len(x)):\n",
    "            for j in range(len(y)):\n",
    "                data[len(x) * i + j][0] = x[i]\n",
    "                data[len(x) * i + j][1] = x[j]\n",
    "        data = Variable(data)\n",
    "        output = self.net(data)\n",
    "        z = output.view(len(x),len(y)).data.numpy()\n",
    "        plt.contourf(x,y,z)\n",
    "        plt.savefig('xor_%d.png' %itr)\n",
    "        plt.show()\n",
    "        \n",
    "    def training(self):\n",
    "        loss_history = []\n",
    "        for i in range(self.epoch):\n",
    "            x, y = self.generate_data()\n",
    "            self.optimizer.zero_grad()   # zero the gradient buffers\n",
    "            output = self.net(x)\n",
    "            loss = self.criterion(output, y)\n",
    "            loss_history.append(loss)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.net.eval()\n",
    "            self.decision_boundary(i)\n",
    "            self.net.train()\n",
    "            print(\"Number of training:\" +str(i))\n",
    "        return loss_history\n",
    "    def test(self):\n",
    "        x, y = self.generate_data()\n",
    "        return x, self.net(x), y\n",
    "   # def test1(self, x):\n",
    "   #     return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training XOR Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=XorNet()\n",
    "model = Model(net, 0.01, 500)\n",
    "loss_history = model.training()\n",
    "plt.scatter(range(len(loss_history)), loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing XOR Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, output, target = model.test()\n",
    "print(\"Randomly Generated Test Data:\")\n",
    "print (data.data[:,:])\n",
    "print(\"Output Comparison with the target output:\")\n",
    "plt.bar(np.array(range(len(output)))-0.14, output, label='output', color='r', width= 0.3)\n",
    "plt.bar(np.array(range(len(output)))+0.14, target, label='target', color='g', width= 0.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "x = np.arange(0.0, 1.001, 0.01)\n",
    "y = np.arange(0.0, 1.001, 0.01)\n",
    "\n",
    "data = torch.zeros(len(x) * len(y), 2)\n",
    "for i in range(len(x)):\n",
    "    for j in range(len(y)):\n",
    "        data[len(x) * i + j][0] = x[i]\n",
    "        data[len(x) * i + j][1] = x[j]\n",
    "data = Variable(data)\n",
    "output = model.test1(data)\n",
    "z = output.view(len(x),len(y)).data.numpy()\n",
    "plt.contourf(x,y,z)\n",
    "plt.savefig('xor_25.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}